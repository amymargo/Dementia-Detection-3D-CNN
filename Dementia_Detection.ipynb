{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pVV1NqdyBQ2P",
        "outputId": "4fdb6c54-7cd2-4c7b-bb45-e4014115bce2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting SimpleITK\n",
            "  Downloading SimpleITK-2.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.9 kB)\n",
            "Downloading SimpleITK-2.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (52.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.4/52.4 MB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: SimpleITK\n",
            "Successfully installed SimpleITK-2.4.0\n"
          ]
        }
      ],
      "source": [
        "!pip install SimpleITK"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import pandas as pd\n",
        "import sys\n",
        "import nibabel as nib\n",
        "import SimpleITK as sitk\n",
        "import numpy as np\n",
        "import os\n",
        "import nibabel as nib\n",
        "import h5py\n",
        "import gc\n",
        "import matplotlib.pyplot as plt\n",
        "import json\n",
        "\n",
        "from torch.utils.data import Subset\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tqdm.auto import tqdm\n",
        "from tqdm import tqdm\n",
        "#from brain_extraction import BrainExtraction\n",
        "from tqdm import tqdm\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "b5Sm7nNYBcTF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wgNiLap5Bg-k",
        "outputId": "ff266c7a-0815-498f-e6fe-7edbfd91914a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q2152pDGB-Tx",
        "outputId": "6fd5099f-597c-49f1-aeb4-9358b873f12b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class ConvBlock(nn.Module):\n",
        "  def __init__(self, in_channel, out_channel, kernel, padding):\n",
        "    super().__init__()\n",
        "    self.in_channels = in_channel\n",
        "    self.out_channels = out_channel\n",
        "    self.kernel = kernel\n",
        "    self.padding = padding\n",
        "\n",
        "    self.blocks = nn.Sequential(\n",
        "        nn.Conv3d(self.in_channels, self.out_channels, kernel_size=self.kernel, padding=self.padding),\n",
        "        nn.BatchNorm3d(self.out_channels),\n",
        "        nn.MaxPool3d(self.kernel,padding=self.padding),\n",
        "        nn.ReLU()\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    #for i in range(self.num_conv):\n",
        "    return self.blocks(x)\n",
        "\n",
        "class SkipConnectionConvBlock(nn.Module):\n",
        "  def __init__(self, in_channel, out_channel, kernel, padding, num_conv_blocks):\n",
        "    super().__init__()\n",
        "    self.in_channels = in_channel\n",
        "    self.out_channels = out_channel\n",
        "    self.kernel = kernel\n",
        "    self.padding = padding\n",
        "    self.num_conv_blocks = num_conv_blocks\n",
        "\n",
        "    self.conv_blocks = nn.ModuleList()\n",
        "    self.batch_norms = nn.ModuleList()\n",
        "    if self.num_conv_blocks % 2 == 1:\n",
        "      raise Exception('number of conv blocks should be even')\n",
        "\n",
        "    self.conv_blocks.append(\n",
        "        torch.nn.Conv3d(\n",
        "            self.in_channels,\n",
        "            self.out_channels,\n",
        "            kernel_size=self.kernel,\n",
        "            padding=self.padding,\n",
        "            device=device\n",
        "        )\n",
        "    )\n",
        "    self.batch_norms.append(nn.BatchNorm3d(self.out_channels, device=device))\n",
        "    skip_input_channel = self.in_channels\n",
        "    for i in range(1, self.num_conv_blocks):\n",
        "        if i % 2 == 0:\n",
        "            input_channel = self.out_channels + skip_input_channel\n",
        "            skip_input_channel = self.out_channels\n",
        "        else:\n",
        "            input_channel = self.out_channels\n",
        "        self.conv_blocks.append(\n",
        "            torch.nn.Conv3d(\n",
        "                input_channel,\n",
        "                self.out_channels,\n",
        "                kernel_size=self.kernel,\n",
        "                padding=self.padding,\n",
        "                device=device\n",
        "            )\n",
        "        )\n",
        "        self.batch_norms.append(nn.BatchNorm3d(self.out_channels, device=device))\n",
        "\n",
        "    self.maxpool = nn.MaxPool3d(self.kernel,padding=self.padding)\n",
        "    self.relu = nn.ReLU()\n",
        "\n",
        "  def forward(self, x):\n",
        "    skip_channel_input = x\n",
        "    conv_block_output = None\n",
        "    for i in range(self.num_conv_blocks):\n",
        "        if i != 0 and i % 2 == 0:\n",
        "            current_input = torch.concat([skip_channel_input, conv_block_output], dim=1)\n",
        "        elif i == 0:\n",
        "            current_input = x\n",
        "        else:\n",
        "            current_input = conv_block_output\n",
        "        conv_block_output1 = self.conv_blocks[i](current_input)\n",
        "        del current_input\n",
        "        conv_block_output2 = self.batch_norms[i](conv_block_output1)\n",
        "        del conv_block_output1\n",
        "        conv_block_output = self.relu(conv_block_output2)\n",
        "        del conv_block_output2\n",
        "\n",
        "    x = conv_block_output\n",
        "    #maxpool, avgpool\n",
        "    return x\n",
        "\n",
        "class CNNModel(torch.nn.Module):\n",
        "\n",
        "  def __init__(self, in_channel, start_out_channel, num_classes, H,W,Z,number_of_blocks=2):\n",
        "    super().__init__()\n",
        "    self.num_classes = num_classes\n",
        "    self.number_of_blocks = number_of_blocks\n",
        "    self.out_channels = [start_out_channel * (2**i) for i in range(self.number_of_blocks)] #consider changing scaling for each layer so that theyre the same size\n",
        "    self.in_channels = [in_channel] + self.out_channels[:-1]\n",
        "\n",
        "    self.kernel_size = [3]*number_of_blocks\n",
        "    self.padding=[1]*number_of_blocks #3//2\n",
        "\n",
        "    self.skip_connection_block = SkipConnectionConvBlock(self.in_channels[0], self.out_channels[0], self.kernel_size[0], self.padding[0], 4)\n",
        "    self.in_channels[0] = self.out_channels[0]\n",
        "    self.resnet_blocks = nn.ModuleList([\n",
        "        ConvBlock(self.in_channels[i], self.out_channels[i], self.kernel_size[i], self.padding[i]) for i in range(self.number_of_blocks)\n",
        "    ])\n",
        "    #self.flatten = nn.Flatten()\n",
        "\n",
        "    self.fc = nn.Linear(self.out_channels[-1], self.num_classes, device=device)\n",
        "    self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.skip_connection_block(x)\n",
        "    for i in range(self.number_of_blocks):\n",
        "        x = self.resnet_blocks[i](x)\n",
        "    x1 = x.mean(dim=(2,3,4)) #average pool\n",
        "    out = self.fc(x1)\n",
        "    out = self.sigmoid(out)\n",
        "    return out"
      ],
      "metadata": {
        "id": "t19iI2KSB2VI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class NumpyDataset(Dataset):#old block\n",
        "    def __init__(self, data, labels):\n",
        "        self.data = [torch.from_numpy(np.expand_dims(x, axis=0)).float() for x in data]\n",
        "        self.labels = torch.from_numpy(labels).long()\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        return self.data[index], self.labels[index]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)"
      ],
      "metadata": {
        "id": "KfxJM0ryCBRT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomDirDataset(Dataset):\n",
        "    def __init__(self, data_path_list, labels):\n",
        "        self.data = data_path_list\n",
        "        self.labels = torch.from_numpy(labels).long()\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        img = nib.load(self.data[index])\n",
        "        img = img.get_fdata()\n",
        "        img = np.expand_dims(img, axis=0)\n",
        "        img = torch.from_numpy(img).float()\n",
        "        return img, self.labels[index]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)"
      ],
      "metadata": {
        "id": "Fubw2EHbCDI8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#hd5 image loader\n",
        "\n",
        "IMAGE_DIR = '/content/drive/MyDrive/DL_CNN/OAS_STRIP'\n",
        "LABEL_PATH = '/content/drive/MyDrive/DL_CNN/OAS_LABELS/data_labels.csv'\n",
        "\n",
        "df = pd.read_csv(LABEL_PATH)\n",
        "\n",
        "def create_hdf5_dataset(folder_path=IMAGE_DIR, output_file='brain_images.h5'):\n",
        "    state_dict = {row['MRI ID']: (row['Group']!='Nondemented') for idx, row in df.iterrows()}\n",
        "    total_images = 0\n",
        "    file_mapping = []\n",
        "\n",
        "    for patient_visit in sorted(os.listdir(folder_path)):\n",
        "        if 'MR' in patient_visit:\n",
        "                if patient_visit not in state_dict:\n",
        "                    continue\n",
        "                patient_dir = os.path.join(folder_path, patient_visit)\n",
        "                for root, _, files in os.walk(patient_dir):\n",
        "                    for file in files:\n",
        "                        if 'n4' in file and file.endswith('.gz'):\n",
        "                            file_path = os.path.join(root, file)\n",
        "                            if os.path.exists(file_path):\n",
        "                                file_mapping.append((patient_visit, file_path))\n",
        "                                total_images += 1\n",
        "\n",
        "    print(f\"{total_images} images\")\n",
        "\n",
        "    first_img = nib.load(file_mapping[0][1]).get_fdata()\n",
        "    first_img = np.swapaxes(np.swapaxes(first_img, 0, 2), 1, 2)\n",
        "    img_shape = first_img.shape\n",
        "    del first_img\n",
        "    gc.collect()\n",
        "\n",
        "    with h5py.File(output_file, 'w') as f:\n",
        "        images_dataset = f.create_dataset('images', shape=(total_images,) + img_shape,dtype='float32', chunks=(1,) + img_shape,compression='gzip', compression_opts=4)\n",
        "        labels_dataset = f.create_dataset('labels',shape=(total_images,),dtype='bool')\n",
        "        patient_ids = f.create_dataset('patient_ids',shape=(total_images,),dtype=h5py.special_dtype(vlen=str))\n",
        "        for idx, (patient_visit, file_path) in enumerate(tqdm(file_mapping)):\n",
        "                target_image = nib.load(file_path)\n",
        "                target_image = target_image.get_fdata()\n",
        "                target_image = np.swapaxes(np.swapaxes(target_image, 0, 2), 1, 2)\n",
        "\n",
        "                images_dataset[idx] = target_image\n",
        "                labels_dataset[idx] = state_dict[patient_visit]\n",
        "                patient_ids[idx] = patient_visit\n",
        "\n",
        "                del target_image\n",
        "                gc.collect()\n",
        "                torch.cuda.empty_cache()\n",
        "\n",
        "        f.attrs['total_images'] = total_images\n",
        "        f.attrs['image_shape'] = img_shape\n",
        "\n",
        "create_hdf5_dataset()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WqA8kEeACYTV",
        "outputId": "805b704b-b70c-4ff3-8e61-314186ce59c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1368 images\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1368/1368 [43:34<00:00,  1.91s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#hd5 block\n",
        "\n",
        "class HD5Dataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, h5_file='brain_images.h5'):\n",
        "        self.h5_file = h5py.File(h5_file, 'r')\n",
        "        self.images = self.h5_file['images']\n",
        "        self.labels = self.h5_file['labels']\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def __getitem__(self, idx): #[128, 256, 256]\n",
        "        image = torch.from_numpy(self.images[idx]).float() #[1, 128, 256, 256]\n",
        "        image = image.unsqueeze(0)\n",
        "        label = torch.tensor(self.labels[idx]).long()\n",
        "        return image, label\n",
        "\n",
        "    def __del__(self):\n",
        "        self.h5_file.close()\n",
        "\n",
        "def create_data_loaders(batch_size=32):\n",
        "    full_dataset = HD5Dataset()\n",
        "    total_size = len(full_dataset)\n",
        "    train_size = int(0.7 * total_size)\n",
        "    val_size = int(0.15 * total_size)\n",
        "    test_size = total_size - train_size - val_size\n",
        "    indices = list(range(total_size))\n",
        "    train_indices, temp_indices = train_test_split(indices, train_size=train_size, random_state=42)\n",
        "    val_indices, test_indices = train_test_split(temp_indices, train_size=val_size, random_state=42)\n",
        "\n",
        "    train_dataset = Subset(full_dataset, train_indices)\n",
        "    val_dataset = Subset(full_dataset, val_indices)\n",
        "    test_dataset = Subset(full_dataset, test_indices)\n",
        "\n",
        "    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "    val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
        "    test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "    return train_loader, val_loader, test_loader\n",
        "\n",
        "train_loader, val_loader, test_loader = create_data_loaders(batch_size=4)\n",
        "dataset = HD5Dataset()\n",
        "dataloader = torch.utils.data.DataLoader(dataset, batch_size=4, shuffle=True)"
      ],
      "metadata": {
        "id": "vGYRQSeUCbgx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = CNNModel(1, 16, 1, 256,128,256,3) #re-run after GPU limit reached\n",
        "model.to(device)"
      ],
      "metadata": {
        "id": "UUcKK95RXZk0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.BCELoss() #re-run after GPU limit reached\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=3e-4)"
      ],
      "metadata": {
        "id": "nlY3wkW_C-js"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gc\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "aGKFO1v3cDFi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#new training block ; this block was re-run beyond the first 50 epoch run, and was cut off when Colab limit reached\n",
        "\n",
        "save_dir = '/content/drive/MyDrive/DL_CNN/training_history'\n",
        "os.makedirs(save_dir, exist_ok=True)\n",
        "def train_epoch(model, dataloader, criterion, optimizer, device):\n",
        "    model.train()\n",
        "    all_losses = []\n",
        "\n",
        "    for i, (x, y) in tqdm(enumerate(dataloader)):\n",
        "        x = x.to(device)\n",
        "        y = y.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        output = model(x)\n",
        "        loss = criterion(output[:, 0], y.float())\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        loss_value = loss.detach().item()\n",
        "        all_losses.append(loss_value)\n",
        "        del x, y, output, loss\n",
        "        torch.cuda.empty_cache()\n",
        "        gc.collect()\n",
        "\n",
        "    return sum(all_losses)/len(all_losses)\n",
        "\n",
        "def validate_epoch(model, val_loader, criterion, device):\n",
        "    model.eval()\n",
        "    val_losses = []\n",
        "    with torch.no_grad(): #minimize memory load\n",
        "        for i, (x, y) in tqdm(enumerate(val_loader)):\n",
        "            x = x.to(device)\n",
        "            y = y.to(device)\n",
        "            output = model(x)\n",
        "            loss = criterion(output[:, 0], y.float())\n",
        "            val_losses.append(loss.item())\n",
        "            del x, y, output, loss\n",
        "            torch.cuda.empty_cache()\n",
        "            gc.collect()\n",
        "\n",
        "    return sum(val_losses)/len(val_losses)\n",
        "\n",
        "val_losses_history = []\n",
        "train_losses_history = []\n",
        "\n",
        "for epoch in range(50):\n",
        "    model.train()\n",
        "    all_losses = []\n",
        "\n",
        "    for i, (x, y) in tqdm(enumerate(train_loader), desc=f\"Training epoch {epoch}\"):\n",
        "        torch.cuda.empty_cache()\n",
        "        gc.collect()\n",
        "        x = x.to(device)\n",
        "        y = y.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(x)\n",
        "        loss = criterion(output[:, 0], y.float())\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        all_losses.append(loss.detach().item())\n",
        "        del x, y, output, loss\n",
        "\n",
        "    train_loss = sum(all_losses)/len(all_losses)\n",
        "    train_losses_history.append(float(train_loss))\n",
        "    print(f\"Train Loss: {train_loss:.5f} for epoch: {epoch}\")\n",
        "    model.eval()\n",
        "    val_losses = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for i, (x, y) in tqdm(enumerate(val_loader), desc=f\"Validation epoch {epoch}\"):\n",
        "            torch.cuda.empty_cache()\n",
        "            gc.collect()\n",
        "            x = x.to(device)\n",
        "            y = y.to(device)\n",
        "            output = model(x)\n",
        "            loss = criterion(output[:, 0], y.float())\n",
        "            val_losses.append(loss.item())\n",
        "            del x, y, output, loss\n",
        "    val_loss = sum(val_losses)/len(val_losses)\n",
        "    val_losses_history.append(float(val_loss))\n",
        "    print(f\"Val Loss: {val_loss:.5f} for epoch: {epoch}\")\n",
        "    history = {'train_losses': train_losses_history,'val_losses': val_losses_history,'last_epoch': epoch}\n",
        "\n",
        "    with open(f'{save_dir}/loss_history.json', 'w') as f:\n",
        "        json.dump(history, f)\n",
        "    torch.cuda.empty_cache()\n",
        "    gc.collect()\n",
        "\n",
        "def plot_training_history(history_path):\n",
        "    with open(history_path, 'r') as f:\n",
        "        history = json.load(f)\n",
        "\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.plot(history['train_losses'], label='Training Loss', marker='o')\n",
        "    plt.plot(history['val_losses'], label='Validation Loss', marker='o')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.title('Training and Validation Loss Over Time')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "\n",
        "plot_training_history(f'{save_dir}/loss_history.json')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ax-c6jG-dcQE",
        "outputId": "e4c48dee-5243-4f72-fc6f-b38d32a76020"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Starting epoch 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining epoch 0: 0it [00:00, ?it/s]<ipython-input-8-d4b91fb22c17>:17: DeprecationWarning: In future, it will be an error for 'np.bool_' scalars to be interpreted as an index\n",
            "  label = torch.tensor(self.labels[idx]).long()\n",
            "Training epoch 0: 240it [09:16,  2.32s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.5877 for epoch: 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation epoch 0: 52it [00:48,  1.07it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val Loss: 0.6272 for epoch: 0\n",
            "\n",
            "Starting epoch 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training epoch 1: 240it [09:16,  2.32s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.5826 for epoch: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation epoch 1: 52it [00:48,  1.07it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val Loss: 0.9891 for epoch: 1\n",
            "\n",
            "Starting epoch 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training epoch 2: 72it [02:46,  2.30s/it]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#testing\n",
        "model.eval()\n",
        "test_losses = []\n",
        "test_predictions = []\n",
        "test_labels = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for i, (x, y) in tqdm(enumerate(test_loader)):\n",
        "        x = x.to(device)\n",
        "        y = y.to(device)\n",
        "        output = model(x)\n",
        "        loss = criterion(output[:, 0], y.float())\n",
        "        test_losses.append(loss.item())\n",
        "        test_predictions.extend(output.cpu().numpy()[:, 0])\n",
        "        test_labels.extend(y.cpu().numpy())\n",
        "\n",
        "test_predictions = np.array(test_predictions)\n",
        "test_labels = np.array(test_labels)\n",
        "\n",
        "binary_predictions = (test_predictions >= 0.5).astype(int)\n",
        "\n",
        "correct = (binary_predictions == test_labels).sum()\n",
        "accuracy = correct / len(test_labels)\n",
        "\n",
        "print(f\"Test Accuracy: {accuracy:.5f}\")\n",
        "print(f\"Average Test Loss: {np.mean(test_losses):.5f}\")\n",
        "\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "print(classification_report(test_labels, binary_predictions))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EOPZIxTkmabM",
        "outputId": "349de91d-287d-4d38-90c3-f4a31773e076"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r0it [00:00, ?it/s]<ipython-input-8-d4b91fb22c17>:17: DeprecationWarning: In future, it will be an error for 'np.bool_' scalars to be interpreted as an index\n",
            "  label = torch.tensor(self.labels[idx]).long()\n",
            "52it [00:38,  1.37it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 0.6990\n",
            "Average Test Loss: 0.5894\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.44      0.58        95\n",
            "           1       0.66      0.92      0.77       111\n",
            "\n",
            "    accuracy                           0.70       206\n",
            "   macro avg       0.74      0.68      0.67       206\n",
            "weighted avg       0.73      0.70      0.68       206\n",
            "\n",
            "\n",
            "Confusion Matrix:\n",
            "[[ 42  53]\n",
            " [  9 102]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    }
  ]
}